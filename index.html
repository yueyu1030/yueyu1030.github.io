<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Yue Yu


</title>
<meta name="description" content="">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Nunito:300,400,500,700|Nunito+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://combinatronics.io/jwarby/pygments-css/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ‘£</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXXXX"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-XXXXXXXXX');
</script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

  <!-- Nav Bar -->
  <nav id="navbar"
    class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://yueyu1030.github.io/">
        Yue Yu
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav"
        aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
            <a class="nav-link" href="/assets/pdf/cv.pdf">
              CV
              
            </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
            <a class="nav-link" href="/services/">
              Misc
              
            </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
            <a class="nav-link" href="/publications/">
              Publications
              
            </a>
          </li>
          
          
          
          
          
          
          <div class="toggle-container">
            <a id="light-toggle">
              <i class="fas fa-moon"></i>
              <i class="fas fa-sun"></i>
            </a>
          </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>

    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
      Yue Yu
    </h1>
    <p class="desc"><a href="https://cse.gatech.edu/">School of CSE, Georgia Institute of Technology</a></p>
  </header>

  <article>
    
    <div class="profile float-right">
      
      <img class="img-fluid z-depth-1 rounded" src="/assets/img/image.jpg">
      
       <p class="desc text-center">Taken in Anchorage, Alsaka</p>
      
      <div class="address">
        <p>Room E1317, CODA Building</p> <p>756 W Peachtree St NW, Atlanta, GA 30308</p>

      </div>
      
    </div>
    

    <div class="clearfix">
      <p>Hello! I am a final-year PhD student at School of Computational Science and Engineering, <a href="https://gatech.edu/">Georgia Institute of Technology</a>. I mainly work on the intersection of Large Language Models and Data-centric AI.</p>

<p>Before joining Georgia Tech, I obtained my bachelorâ€™s degree (with honors) from the Department of Electronic Engineering, <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a> in 2019, where I have also worked on spatio-temporal data mining under the supervision of <a href="http://fi.ee.tsinghua.edu.cn/~liyong/">Dr. Yong Li</a>.</p>

<p>Feel free to drop me an email (<code class="language-plaintext highlighter-rouge">yueyu at gatech dot edu</code>) if you have any questions about my research, or general discussions about NLP.</p>

<!-- **<span style="color:red">I will graduate soon and am on the industry job market now. Feel free to reach out if there is a good fit!</span>** -->


    </div>

    
      <br>
      <head>
  <style>
    body {
      font-family: times, Helvetica, Arial, sans-serif;
    }
  </style>
</head>
<div class="educations">
  <h2>Educations</h2>
  <dt>Georgia Institute of Technology (<dc>2019 - Present</dc>) </dt> <img src="georgia_tech.png" width="160" style="float:right; position:relative;right:10px;top:-30px" > 
    <dd><b>Ph.D.</b> in Computational Science and Engineering</dd>
    <dd><b>GPA</b>: 4.00/4.00</dd>
    <dd><b>Thesis Topic</b>: Towards Efficiently and Effectively Harnessing Large Pre-trained Models via Data-centric Lens. </dd>
    <!-- <dd><b>Research Focus</b>: Large Language Models, Active/Interactive Learning, .</dd> -->
    <dd><b>Advisor</b>: Prof. Chao Zhang</dd>
    <p></p>
  <dt>Tsinghua University (<dc>2015 - 2019</dc>) </dt> <img src="tsinghua.png" width="140" style="float:right; position:relative;right:10px;top:-20px" > 
    <dd><b>B.Eng.</b> in Electronic Engineering</dd>
    <dd><b>GPA</b>: 3.87/4.00 (Outstanding Graduate)</dd>
    <dd><b>Research Focus</b>: Spatio-temporal Data Mining [<a href="https://dl.acm.org/doi/abs/10.1145/3308558.3313453">WWW 2019</a>, <a href="https://dl.acm.org/doi/10.1145/3411817">UbiComp 2020</a>], Recommender Systems [<a href="https://dl.acm.org/doi/10.1145/3314398">UbiComp 2019</a>].</dd>
    <dd><b>Advisor</b>: Prof. Yong Li</dd>
</dl>
</div><br>

    

    
      <br>
      
<div class="Industrial Experience">
  <h2>Industrial Experience</h2>
  <dl>
    <dt>Meta (May 2024 - Aug 2024)</dt>
    <dd>
      <img src="Meta.png" width="190" style="float:right; position:relative; right:-20px; top:-30px;">
      Research Intern, GenAI (Llama Post-training Team)
    </dd>
    <dd><b>Host</b>: Rui Hou, <b>Manager</b>: Melanie Kambadur</dd>
    <dd><b>Topic</b>: Self-Critiquing Reward Models [<a href=""><b>Preprint</b></a>].</dd>
    <br>

    <dt>NVIDIA (Jan 2024 - May 2024)</dt>
    <dd>
      <img src="NVIDIA.png" width="190" style="float:right; position:relative; right:-20px; top:-30px;">
      Research Intern, Applied Deep Learning Research Group
    </dd>
    <dd><b>Host</b>: Wei Ping, <b>Manager</b>: Mohammad Shoeybi</dd>
    <dd><b>Topic</b>: LLM Instruction Fine-tuning for Zero-shot Retrieval-Augmented Generation [<a href="https://arxiv.org/abs/2407.02485"><b>NeurIPS 2024</b></a>].</dd>
    <br>

    <dt>Google Research (May 2023 - Aug 2023)</dt>
    <dd>
      <img src="Google.png" width="190" style="float:right; position:relative; right:-20px; top:-5px;">
      Research Intern, News Understanding Group
    </dd>
    <dd><b>Host</b>: Jiaming Shen, <b>Manager</b>: Jialu Liu</dd>
    <dd><b>Topic</b>: LLM In-context Learning with Rationales [<a href="https://arxiv.org/abs/2311.07099"><b>ACL 2024</b></a>].</dd>
    <br>

    <dt>Microsoft Research (May 2021 - Aug 2021)</dt>
    <dd>
      <img src="microsoft.png" width="190" style="float:right; position:relative; right:-20px; top:5px;">
      Research Intern, Productivity and Intelligence Group
    </dd>
    <dd><b>Mentor</b>: Chenyan Xiong, <b>Manager</b>: Arnold Overwijk</dd>
    <dd><b>Topic</b>: Zero-shot Dense Text Retrieval [<a href="https://aclanthology.org/2022.emnlp-main.95.pdf"><b>EMNLP 2022</b></a>].</dd>
    <br>

    <dt>IQVIA (May 2020 - Aug 2020)</dt>
    <dd>
      <img src="iqvia.png" width="190" style="float:right; position:relative; right:-20px; top:-0px;">
      Research Intern, Analytics Center of Excellence
    </dd>
    <dd><b>Mentor</b>: Cao (Danica) Xiao</dd>
    <dd><b>Topic</b>: Knowledge-enhanced Drug Interaction Prediction [<a href="https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btab207/6189090"><b>Bioinformatics 2021</b></a>].</dd>
  </dl>
</div>

<!-- <div class="Industrial Experience">
  <h2>Industrial Experience</h2>
     <dl>
    <dt>Meta (May 2024 - Aug 2024) </dt> <img src="NVIDIA.png" width="190" style="float:right; position:relative;right:-20px;top:-115px" > 
    <dd>Research Intern, Generative AI (GenAI) Language Team</dd>
    <dd><b>Host</b>: Rui Hou</dd>
    <p></p>
    <dt>NVIDIA (Jan 2024 - May 2024) </dt> <img src="NVIDIA.png" width="190" style="float:right; position:relative;right:-20px;top:-25px" > 
    <dd>Research Intern, Applied Deep Learning Research Group</dd>
    <dd><b>Host</b>: Wei Ping, <b>Manager</b>: Mohammad Shoeybi</dd>
    <dd><b>Topic</b>: Fine-tuning Large Language Model for Retrieval-Augmented Generation [<a href=""><b>arXiv preprint</b></a>].</dd>
    <p></p>
    <dt>Google Research (May 2023 - Aug 2023) </dt> <img src="Google.png" width="190" style="float:right; position:relative;right:-20px;top:-5px" > 
    <dd>Research Intern, News Understanding Group</dd>
    <dd><b>Host</b>: Jiaming Shen, <b>Manager</b>: Jialu Liu</dd>
    <dd><b>Topic</b>: Large Language Model In-context Learning [<a href="https://arxiv.org/abs/2311.07099"><b>ACL 2024</b></a>].</dd>
    <p></p>
  <dt>Microsoft Research (May 2021 - Aug 2021) </dt> <img src="microsoft.png" width="190" style="float:right; position:relative;right:-20px;top:+5px" > 
    <dd>Research Intern, Productivity and Intelligence Group</dd>
    <dd><b>Mentor</b>: Chenyan Xiong, <b>Manager</b>: Arnold Overwijk</dd>
    <dd><b>Topic</b>: Zero-shot Dense Text Retrieval [<a href="https://aclanthology.org/2022.emnlp-main.95.pdf"><b>EMNLP 2022</b></a>].</dd>
    <p></p>
  <dt>IQVIA (May 2020 - Aug 2020)</dt> <img src="iqvia.png" width="190" style="float:right; position:relative;right:-20px;top:-5px" > 
    <dd>Research Intern, Analytics Center of Excellence</dd>
    <dd><b>Mentor</b>: Cao (Danica) Xiao</dd>
    <dd><b>Topic</b>: Knowledge-enhanced Drug Interaction Prediction [<a href="https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btab207/6189090"><b>Bioinformatics 2021</b></a>].</dd>
</dl>
</div><br> -->

    
    
    
    <head>
  <style>
    body {
      font-family: Helvetica, Arial, sans-serif;
    }
  </style>
</head>

<div class="news">
  <h2>News</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Sep 25, 2024</th>
          <td>
            
              Two papers are accepted to NeurIPS 2024 and Three papers are accepted to EMNLP 2024. Congratulations!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">May 16, 2024</th>
          <td>
            
              6 papers are accepted to ACL 2024 (4 Main Conf, 2 Findings).

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Oct 25, 2023</th>
          <td>
            
              Honored to receive the NeurIPS 2023 Scholar award!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Sep 22, 2023</th>
          <td>
            
              3 papers are accepted to NeurIPS 2023. Thanks for my collaborators!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">May 16, 2023</th>
          <td>
            
              Checkout the recent publications: 2 first-author papers are accepted to ACL 2023 (1 Main Conf, 1 Findings), and 3 coauthored papers are accepted to KDD 2023. Thanks and Congratulations for my collaborators!

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
    
    <div class="publications">
  <h2>Selected Publications</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>
  <!-- <div class="col-sm-2 abbr">
    
    
    <abbr class="badge">NeurIPS</abbr>
    
    
  </div> -->

  <div id="yu2024rankrag" class="col-sm-8">
    
    <div class="title"><b>RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      <em>Yue Yu</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Wei Ping,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Zihan Liu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Boxin Wang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Jiaxuan You,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Chao Zhang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Mohammad Shoeybi,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Bryan Catanzaro
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>NeurIPS</em>, 
      <!-- /*(NeurIPS)*/ -->
      <!-- The Thirty-eighth Conference on Neural Information Processing Systems -->
      
      
      2024.  
      
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      
      <a href="http://arxiv.org/abs/2407.02485" class="btn btn-sm z-depth-0" role="button"
        target="_blank">arXiv</a>
      
      
      
      
      
      <a href="https://openreview.net/forum?id=S1fc92uemC" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
      
      
      
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>
  <!-- <div class="col-sm-2 abbr">
    
    
    <abbr class="badge">NeurIPS (D&B Track)</abbr>
    
    
  </div> -->

  <div id="yu2023large" class="col-sm-8">
    
    <div class="title"><b>Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      <em>Yue Yu*</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yuchen Zhuang*,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Jieyu Zhang*,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Yu Meng,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Alexander Ratner,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Ranjay Krishna,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Jiaming Shen,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Chao Zhang
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>NeurIPS (D&B Track)</em>, 
      <!-- /*(NeurIPS (D&B Track))*/ -->
      <!-- Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track -->
      
      
      2023.  
      
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      
      <a href="http://arxiv.org/abs/2306.15895" class="btn btn-sm z-depth-0" role="button"
        target="_blank">arXiv</a>
      
      
      
      
      
      <a href="https://openreview.net/forum?id=6hZIfAY9GD" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
      
      
      
      
      <a href="https://github.com/yueyu1030/AttrPrompt" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>
  <!-- <div class="col-sm-2 abbr">
    
    
    <abbr class="badge">ACL</abbr>
    
    
  </div> -->

  <div id="yu2023cold" class="col-sm-8">
    
    <div class="title"><b>Cold-Start Data Selection for Better Few-shot Language Model Fine-tuning: A Prompt-based Uncertainty Propagation Approach</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      <em>Yue Yu</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Rongzhi Zhang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Ran Xu,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Jieyu Zhang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Jiaming Shen,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Chao Zhang
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>ACL</em>, 
      <!-- /*(ACL)*/ -->
      <!-- Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) -->
      
      
      2023.  
      
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
      <a href="https://aclanthology.org/2023.acl-long.141.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
      
      
      
      
      <a href="https://github.com/yueyu1030/Patron" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present PATRON, a prompt-based data selection method for pre-trained language model fine-tuning under cold-start scenarios, i.e., no initial labeled data are available. In PATRON, we design (1) a prompt-based uncertainty propagation approach to estimate the importance of data points and (2) a partition-then-rewrite (PTR) strategy to promote sample diversity when querying for annotations. Experiments on six text classification datasets show that PATRON outperforms the strongest cold-start data selection baselines by up to 6.9%. Besides, with 128 labels only, PATRON achieves 91.0% and 92.1% of the fully supervised performance based on vanilla fine-tuning and prompt-based learning respectively. Our implementation of PATRON will be published upon acceptance.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>
  <!-- <div class="col-sm-2 abbr">
    
    
    <abbr class="badge">EMNLP</abbr>
    
    
  </div> -->

  <div id="yu-etal-2022-coco" class="col-sm-8">
    
    <div class="title"><b>COCO-DR: Combating Distribution Shifts in Zero-Shot Dense Retrieval with Contrastive and Distributionally Robust Learning</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      <em>Yue Yu</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Chenyan Xiong,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Si Sun,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Chao Zhang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Arnold Overwijk
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>EMNLP</em>, 
      <!-- /*(EMNLP)*/ -->
      <!-- Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing -->
      
      
      2022.  
      
      
      (<font color="red">Oral</font>)
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
      <a href="https://aclanthology.org/2022.emnlp-main.95.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
      
      
      
      
      <a href="https://github.com/OpenMatch/COCO-DR" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present a new zero-shot dense retrieval (ZeroDR) method, COCO-DR, to improve the generalization ability of dense retrieval by combating the distribution shifts between source training tasks and target scenarios. To mitigate the impact of document differences, COCO-DR continues pretraining the language model on the target corpora to adapt the model to target distributions via COtinuous COtrastive learning. To prepare for unseen target queries, COCO-DR leverages implicit Distributionally Robust Optimization (iDRO) to reweight samples from different source query clusters for improving model robustness over rare queries during fine-tuning. COCO-DR achieves superior average performance on BEIR, the zero-shot retrieval benchmark. At BERT_Base scale, COCO-DR Base outperforms other ZeroDR models with 60x larger size. At BERT_Large scale, COCO-DR Large outperforms the giant GPT-3 embedding model which has 500x more parameters. Our analysis shows the correlation between COCO-DRâ€™s effectiveness in combating distribution shifts and improving zero-shot accuracy. Our code and model can be found at \urlhttps://github.com/OpenMatch/COCO-DR.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-md-1 abbr" style="margin-right: -1.8rem; margin-left: -1.8rem; margin-top: -0.7rem">

    <abbr class="badge"></abbr>

  </div>
  <!-- <div class="col-sm-2 abbr">
    
    
    <abbr class="badge">NAACL</abbr>
    
    
  </div> -->

  <div id="yu-etal-2022-actune" class="col-sm-8">
    
    <div class="title"><b>AcTune: Uncertainty-Based Active Self-Training for Active Fine-Tuning of Pretrained Language Models</b>
    </div>
    <div class="author">
      
      
      
      
      
      

      
      
      
      <em>Yue Yu</em>,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Lingkai Kong,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Jieyu Zhang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      Rongzhi Zhang,
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Chao Zhang
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Proceedings of <em>NAACL</em>, 
      <!-- /*(NAACL)*/ -->
      <!-- Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies -->
      
      
      2022.  
      
      
      (<font color="red">Oral</font>)
      
      
      
      
    </div>
    

    <!-- <div class="abstract small">
      v
    </div> -->

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
      <a href="https://aclanthology.org/2022.naacl-main.102.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
      
      
      
      
      <a href="https://github.com/yueyu1030/actune" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
      
      
      
      
    </div>



    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Although fine-tuning pre-trained language models (PLMs) renders strong performance in many NLP tasks, it relies on excessive labeled data. Recently, researchers have resorted to active fine-tuning for enhancing the label efficiency of PLM fine-tuning, but existing methods of this type usually ignore the potential of unlabeled data. We develop AcTune, a new framework that improves the label efficiency of active PLM fine-tuning by unleashing the power of unlabeled data via self-training. AcTune switches between data annotation and model self-training based on uncertainty: the unlabeled samples of high-uncertainty are selected for annotation, while the ones from low-uncertainty regions are used for model self-training. Additionally, we design (1) a region-aware sampling strategy to avoid redundant samples when querying annotations and (2) a momentum-based memory bank to dynamically aggregate the modelâ€™s pseudo labels to suppress label noise in self-training. Experiments on 6 text classification datasets show that AcTune outperforms the strongest active learning and self-training baselines and improves the label efficiency of PLM fine-tuning by 56.2% on average. Our implementation is available at \urlhttps://github.com/yueyu1030/actune.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li></ol>
</div>

    

    
    <div class="social">
      <div class="contact-icons">
        <a href="mailto:%79%75%65%79%75@%67%61%74%65%63%68.%65%64%75"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=zQ3Jh6UAAAAJ"
    target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/yueyu1030" target="_blank" title="GitHub"><i
        class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/yue-yu-b75553115" target="_blank"
    title="LinkedIn"><i class="fab fa-linkedin"></i></a>
<a href="https://twitter.com/yue___yu" target="_blank"
    title="Twitter"><i class="fab fa-twitter"></i></a>









<a href="/assets/pdf/cv.pdf" target="_blank" title="CV"><i
        class="ai ai-cv big-icon"></i></a>
      </div>
      <div class="contact-note"></div>
    </div>
    
  </article>

</div>
    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2024 Yue  Yu.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
